{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Ensemble Learning: From Random Forest to Gradient Boosting ðŸŒ³\n",
    "\n",
    "**Ensemble learning** is a technique that combines multiple machine learning models to produce a more powerful and accurate model. Instead of relying on a single model, we leverage the \"wisdom of the crowd\" by aggregating the predictions of several base estimators.\n",
    "\n",
    "This notebook will compare the performance of a single Decision Tree against two popular tree-based ensemble methods on the Titanic dataset:\n",
    "\n",
    "1.  **Bagging (Random Forest):** Models are built independently and in parallel. Their predictions are then combined through a voting process. This method is excellent at reducing variance and preventing overfitting.\n",
    "2.  **Boosting (Gradient Boosting):** Models are built sequentially. Each new model focuses on correcting the errors made by the previous ones, gradually improving the overall prediction.\n",
    "\n",
    "---"
   ],
   "id": "ccf49dc2520f93b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Predicting Survival on the Titanic\n",
    "\n",
    "Our goal is to predict whether a passenger survived the Titanic disaster based on features like their class, sex, and age.\n",
    "\n",
    "First, we load and prepare the data. The `Name` column is dropped as it's not a useful feature, and the categorical `Sex` column is converted to numerical values.\n"
   ],
   "id": "ea136246a848d126"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-30T16:17:19.647181Z",
     "start_time": "2025-09-30T16:17:19.637991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('titanic.csv')\n",
    "df.head()"
   ],
   "id": "b17f07de7514c085",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                             Mr. Owen Harris Braund   \n",
       "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
       "2         1       3                              Miss. Laina Heikkinen   \n",
       "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
       "4         0       3                            Mr. William Henry Allen   \n",
       "\n",
       "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
       "0    male  22.0                        1                        0   7.2500  \n",
       "1  female  38.0                        1                        0  71.2833  \n",
       "2  female  26.0                        0                        0   7.9250  \n",
       "3  female  35.0                        1                        0  53.1000  \n",
       "4    male  35.0                        0                        0   8.0500  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Owen Harris Braund</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. John Bradley (Florence Briggs Thayer) Cum...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Laina Heikkinen</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. Jacques Heath (Lily May Peel) Futrelle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. William Henry Allen</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T16:17:19.687165Z",
     "start_time": "2025-09-30T16:17:19.680153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preprocessing\n",
    "df.drop(\"Name\", axis='columns', inplace=True)\n",
    "df['Sex'] = df['Sex'].map({'male':1, 'female':2})\n",
    "df.head()"
   ],
   "id": "1c0a1ff8113615ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Survived  Pclass  Sex   Age  Siblings/Spouses Aboard  \\\n",
       "0         0       3    1  22.0                        1   \n",
       "1         1       1    2  38.0                        1   \n",
       "2         1       3    2  26.0                        0   \n",
       "3         1       1    2  35.0                        1   \n",
       "4         0       3    1  35.0                        0   \n",
       "\n",
       "   Parents/Children Aboard     Fare  \n",
       "0                        0   7.2500  \n",
       "1                        0  71.2833  \n",
       "2                        0   7.9250  \n",
       "3                        0  53.1000  \n",
       "4                        0   8.0500  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, we split our data into training and testing sets.",
   "id": "753f72d4daa14ad1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T16:17:19.800440Z",
     "start_time": "2025-09-30T16:17:19.796423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X = df.drop('Survived', axis='columns')\n",
    "y = df.Survived\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ],
   "id": "f49574d817651ef1",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Baseline Model: A Single Decision Tree\n",
    "\n",
    "To start, let's train a single `DecisionTreeClassifier` to establish a baseline performance."
   ],
   "id": "7e1e9c59af86bc45"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T16:17:19.849224Z",
     "start_time": "2025-09-30T16:17:19.839118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_dt = DecisionTreeClassifier()\n",
    "model_dt.fit(X_train, y_train)\n",
    "y_pred_dt = model_dt.predict(X_test)\n",
    "\n",
    "print(\"--- Decision Tree Report ---\")\n",
    "print(classification_report(y_test, y_pred_dt))"
   ],
   "id": "512f6e285a63a853",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Decision Tree Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82       166\n",
      "           1       0.71      0.72      0.72       101\n",
      "\n",
      "    accuracy                           0.78       267\n",
      "   macro avg       0.77      0.77      0.77       267\n",
      "weighted avg       0.78      0.78      0.78       267\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The single decision tree achieves an accuracy of **77%**.",
   "id": "88cb41738b0fa555"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Ensemble Method 1: Random Forest (Bagging)\n",
    "\n",
    "A **Random Forest** builds multiple decision trees in parallel on different subsets of the data (bagging) and with different subsets of features. The final prediction is made by averaging the predictions of all the individual trees. This process helps to reduce overfitting and improve generalization."
   ],
   "id": "ad56ccf3ccf433f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T16:17:19.967326Z",
     "start_time": "2025-09-30T16:17:19.855587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=100)\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "print(\"--- Random Forest Report ---\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ],
   "id": "7f30ea33fba0d6a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Random Forest Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82       166\n",
      "           1       0.73      0.65      0.69       101\n",
      "\n",
      "    accuracy                           0.78       267\n",
      "   macro avg       0.76      0.75      0.76       267\n",
      "weighted avg       0.77      0.78      0.77       267\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The Random Forest improves the accuracy to **79%**.",
   "id": "d0340db8e4e01fe4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Ensemble Method 2: Gradient Boosting (Boosting)\n",
    "\n",
    "**Gradient Boosting** is another powerful ensemble technique, but it works sequentially. It starts by training a simple model (a \"weak learner,\" usually a shallow decision tree). It then trains a second model to correct the errors of the first. A third model is trained to correct the errors of the second, and so on. Each new tree is an \"expert\" on the mistakes of the previous ones. This step-by-step process of learning from errors allows Gradient Boosting to create a single, highly accurate final model."
   ],
   "id": "7a23c69d9dd1d45b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T16:17:20.068016Z",
     "start_time": "2025-09-30T16:17:19.976219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model_gb = GradientBoostingClassifier(n_estimators=100)\n",
    "model_gb.fit(X_train, y_train)\n",
    "y_pred_gb = model_gb.predict(X_test)\n",
    "\n",
    "print(\"--- Gradient Boosting Report ---\")\n",
    "print(classification_report(y_test, y_pred_gb))"
   ],
   "id": "32dff4aa0106a762",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Gradient Boosting Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86       166\n",
      "           1       0.82      0.67      0.74       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.82      0.79      0.80       267\n",
      "weighted avg       0.82      0.82      0.82       267\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The Gradient Boosting classifier achieves the highest accuracy of **82%**.",
   "id": "7730e7dcddce2cf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "| Model | Accuracy |\n",
    "|:--- |:--- |\n",
    "| Single Decision Tree | 77% |\n",
    "| Random Forest (Bagging) | 79% |\n",
    "| **Gradient Boosting** | **82%** |\n",
    "\n",
    "This comparison highlights the power of ensemble methods:\n",
    "* **Random Forest** improves upon a single Decision Tree by averaging many trees to reduce variance.\n",
    "* **Gradient Boosting** improves performance by building trees sequentially, with each tree correcting the errors of its predecessor.\n",
    "\n",
    "While both are powerful, Gradient Boosting often achieves a higher level of accuracy by focusing on and correcting mistakes in an iterative fashion."
   ],
   "id": "e650be2a795a0e9b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
