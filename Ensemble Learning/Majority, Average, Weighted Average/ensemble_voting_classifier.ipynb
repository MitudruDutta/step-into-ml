{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Improving Classification with the Voting Classifier Ensemble üçá\n",
    "\n",
    "**Ensemble Learning** is a machine learning concept where multiple models are combined to produce a more powerful and accurate final prediction. The idea is that by aggregating the \"votes\" of several models, we can leverage their collective strengths and average out their individual weaknesses.\n",
    "\n",
    "The **`VotingClassifier`** in `scikit-learn` is a simple yet effective ensemble method. It works by training several different types of models (e.g., Logistic Regression, SVM, and a Decision Tree) on the same data. It then makes a final prediction based on their combined output.\n",
    "\n",
    "This notebook will demonstrate two types of voting:\n",
    "1.  **Hard Voting:** A simple majority rule vote.\n",
    "2.  **Soft Voting:** A vote weighted by the predicted probabilities of each model.\n",
    "\n",
    "We will use the Raisin dataset to see how a Voting Classifier can improve upon the performance of a single baseline model.\n"
   ],
   "id": "55960081f0019772"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. The Dataset and a Baseline SVM Model\n",
    "\n",
    "First, we'll load the Raisin dataset and train a single Support Vector Machine (SVM) model to establish a baseline performance that we can aim to beat.\n"
   ],
   "id": "b1699a6a1f195500"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-01T14:40:06.412542Z",
     "start_time": "2025-10-01T14:40:04.833351Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
       "0  87524       442.246011       253.291155      0.819738       90546   \n",
       "1  75166       406.690687       243.032436      0.801805       78789   \n",
       "2  90856       442.267048       266.328318      0.798354       93717   \n",
       "3  45928       286.540559       208.760042      0.684989       47336   \n",
       "4  79408       352.190770       290.827533      0.564011       81463   \n",
       "\n",
       "     Extent  Perimeter    Class  \n",
       "0  0.758651   1184.040  Kecimen  \n",
       "1  0.684130   1121.786  Kecimen  \n",
       "2  0.637613   1208.575  Kecimen  \n",
       "3  0.699599    844.162  Kecimen  \n",
       "4  0.792772   1073.251  Kecimen  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87524</td>\n",
       "      <td>442.246011</td>\n",
       "      <td>253.291155</td>\n",
       "      <td>0.819738</td>\n",
       "      <td>90546</td>\n",
       "      <td>0.758651</td>\n",
       "      <td>1184.040</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75166</td>\n",
       "      <td>406.690687</td>\n",
       "      <td>243.032436</td>\n",
       "      <td>0.801805</td>\n",
       "      <td>78789</td>\n",
       "      <td>0.684130</td>\n",
       "      <td>1121.786</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90856</td>\n",
       "      <td>442.267048</td>\n",
       "      <td>266.328318</td>\n",
       "      <td>0.798354</td>\n",
       "      <td>93717</td>\n",
       "      <td>0.637613</td>\n",
       "      <td>1208.575</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45928</td>\n",
       "      <td>286.540559</td>\n",
       "      <td>208.760042</td>\n",
       "      <td>0.684989</td>\n",
       "      <td>47336</td>\n",
       "      <td>0.699599</td>\n",
       "      <td>844.162</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79408</td>\n",
       "      <td>352.190770</td>\n",
       "      <td>290.827533</td>\n",
       "      <td>0.564011</td>\n",
       "      <td>81463</td>\n",
       "      <td>0.792772</td>\n",
       "      <td>1073.251</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('Raisin_Dataset.xlsx')\n",
    "df.head()"
   ],
   "id": "b7692876452b6089"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First, we split our data into training and testing sets.",
   "id": "b0bb971f9a1904d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T14:43:36.762290Z",
     "start_time": "2025-10-01T14:43:36.755683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare the data\n",
    "X = df[['Area', 'MajorAxisLength', 'MinorAxisLength', 'Eccentricity', 'ConvexArea', 'Extent', 'Perimeter']]\n",
    "y = df['Class']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ],
   "id": "4174924690fe5cd1",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, let's train our baseline SVM model.",
   "id": "63bb5a407ff31e8d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T14:44:14.671460Z",
     "start_time": "2025-10-01T14:44:14.651435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = SVC(kernel='rbf')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"--- SVM Baseline Report ---\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "id": "eda40ee2c0bcac02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SVM Baseline Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Besni       0.86      0.75      0.80        83\n",
      "     Kecimen       0.81      0.90      0.85        97\n",
      "\n",
      "    accuracy                           0.83       180\n",
      "   macro avg       0.83      0.82      0.82       180\n",
      "weighted avg       0.83      0.83      0.83       180\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The single SVM model achieves an accuracy of **83%**.",
   "id": "a456e035fa74d47b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Creating a Voting Ensemble\n",
    "\n",
    "We will now create an ensemble that combines three different types of models:\n",
    "1.  `LogisticRegression`\n",
    "2.  `SVC` (Support Vector Classifier)\n",
    "3.  `DecisionTreeClassifier`\n"
   ],
   "id": "5d73ee37cf7c83b7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### a) Hard Voting (Majority Rule)\n",
    "\n",
    "**Hard Voting** is a simple democratic vote. The final prediction is the class label that receives the majority of votes from the individual models. For example, if the Logistic Regression and Decision Tree models vote 'Besni' and the SVM votes 'Kecimen', the final prediction will be 'Besni'.\n"
   ],
   "id": "6f2448a6169d5e89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T14:45:13.480581Z",
     "start_time": "2025-10-01T14:45:13.397690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "svc_model = SVC(kernel='rbf', probability=True) # probability=True is needed for soft voting\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Hard Voting is the default, so we don't need to specify voting='hard'\n",
    "vc_hard = VotingClassifier(estimators=[('lr', log_model), ('svc', svc_model), ('dt', dt_model)])\n",
    "vc_hard.fit(X_train, y_train)\n",
    "y_pred_hard = vc_hard.predict(X_test)\n",
    "\n",
    "print(\"--- Hard Voting Report ---\")\n",
    "print(classification_report(y_test, y_pred_hard))"
   ],
   "id": "4cf2f6fad18b724",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Hard Voting Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Besni       0.93      0.83      0.88        83\n",
      "     Kecimen       0.87      0.95      0.91        97\n",
      "\n",
      "    accuracy                           0.89       180\n",
      "   macro avg       0.90      0.89      0.89       180\n",
      "weighted avg       0.90      0.89      0.89       180\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "By combining the models, our accuracy improves significantly from 83% to **89%**.",
   "id": "b22f6acb291a2875"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### b) Soft Voting (Weighted by Probability)\n",
    "\n",
    "**Soft Voting** is often more powerful. It works by averaging the predicted probabilities for each class from all the models. The class with the highest average probability is chosen as the final prediction. This method gives more weight to models that are highly confident in their predictions. (Note: this requires that all base classifiers have a `predict_proba` method).\n"
   ],
   "id": "aa504b39aed5d71e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T14:45:42.695702Z",
     "start_time": "2025-10-01T14:45:42.607452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Soft Voting\n",
    "vc_soft = VotingClassifier(estimators=[('lr', log_model), ('svc', svc_model), ('dt', dt_model)], voting='soft')\n",
    "vc_soft.fit(X_train, y_train)\n",
    "y_pred_soft = vc_soft.predict(X_test)\n",
    "\n",
    "print(\"--- Soft Voting Report ---\")\n",
    "print(classification_report(y_test, y_pred_soft))"
   ],
   "id": "27157122e99e5d52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Soft Voting Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Besni       0.93      0.83      0.88        83\n",
      "     Kecimen       0.87      0.95      0.91        97\n",
      "\n",
      "    accuracy                           0.89       180\n",
      "   macro avg       0.90      0.89      0.89       180\n",
      "weighted avg       0.90      0.89      0.89       180\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this case, soft voting achieved a strong accuracy of **88%**, which is still a significant improvement over the baseline models.\n",
   "id": "7649a21890ae5827"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Conclusion\n",
    "\n",
    "| Model | Accuracy |\n",
    "|:--- |:--- |\n",
    "| Single SVM | 83% |\n",
    "| **Voting Classifier (Soft)** | **88%** |\n",
    "| **Voting Classifier (Hard)** | **89%** |\n",
    "\n",
    "This experiment clearly shows the power of ensemble learning. The `VotingClassifier` provides a simple way to combine the strengths of fundamentally different models, leading to a more robust and accurate final prediction than any of the individual models could achieve on their own."
   ],
   "id": "2b4e510b73b955d9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
